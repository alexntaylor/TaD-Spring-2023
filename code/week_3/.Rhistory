# Week 3: descriptive inference for TaD class
# Author: Noel Johnson (adapted from many others---see below)
# Created: 2-7-2022
# Last Updated: 2-5-2023
# Lab adapted from: Lucia Motolinia, Kevin Munger, Patrick Chester,
# Leslie Huang, Pedro L. Rodriguez, and Lucia Motolinia.
## Set up Quanteda
# Clear Global Environment
rm(list = ls())
# devtools::install_github("quanteda/quanteda.corpora")
# Libraries
library(tidyverse)
library(quanteda)
library(quanteda.corpora)
# You can check with this function in base R
validUTF8("This is a sentence")
# You can use the package utf8 by Patrick Perry
# Read about it here: https://cran.r-project.org/web/packages/utf8/index.html
# install.packages("utf8")
library("utf8")
as_utf8("\xF0\x9F\x98\x8D")
print("\xF0\x9F\x98\x8D")
# install.packages("stringi")
library("stringi")
# Use the encoding guesser to guess what this character is
stri_enc_detect("0x00E3")
# How do you convert encodings?
test_str <- "São Paulo"
validUTF8(test_str)
converted_str <- iconv("São Paulo", from = "UTF-8", to = "latin1")
converted_str
validUTF8(converted_str)
#charToRaw converts a character string to raw bytes
charToRaw(converted_str) # Latin-1 encoding
charToRaw(test_str) # UTF-8 encoding
# But what about here?
iconv("ã", from = "UTF-8", to = "ASCII")
# 2.1 Example using data from the corpus of inaugural speeches
tokens <- tokens(data_corpus_inaugural, remove_punct = TRUE)
num_tokens <- sum(lengths(tokens))
inaug_dfm <- dfm(data_corpus_inaugural)
M <- nfeat(inaug_dfm)  # number of types
k <- 54
b <- 0.49
k * (num_tokens)^b
M
plot(log10(1:100), log10(topfeatures(inaug_dfm, 100)),
xlab = "log10(rank)", ylab = "log10(frequency)", main = "Top 100
#Words in U.S. Presidential Inaugural Speech Corpus")
# Fits a linear regression to check if slope is approx -1.0
regression <- lm(log10(topfeatures(inaug_dfm, 100)) ~ log10(1:100))
abline(regression, col = "red")
# Provides R-squared, F-test, and cofficient estimates from regression
summary(regression)
inaug_dfm_nostop <- dfm(data_corpus_inaugural, remove=stopwords("english"))
plot(log10(1:100), log10(topfeatures(inaug_dfm_nostop, 100)),
xlab = "log10(rank)", ylab = "log10(frequency)", main = "Top 100 Words
#in U.S. Presidential Inaugural Speech Corpus (w/o stopwords)")
# Regression to check if slope is approx -1.0
regression <- lm(log10(topfeatures(inaug_dfm_nostop, 100)) ~ log10(1:100))
abline(regression, col = "red")
confint(regression)
summary(regression)
# Cosine similarity--take the dot product of two vectors
# cos = x*y/|x||y|
calculate_cosine_similarity <- function(vec1, vec2) {
nominator <- vec1 %*% vec2
# %*% specifies dot product rather than entry by entry multiplication
# (we could also do: sum(x * y))
denominator <- sqrt(vec1 %*% vec1)*sqrt(vec2 %*% vec2)
return(nominator/denominator)
}
x <- c(1, 2, 3)
y <- c(1, 2, 3)
# what should we get?
calculate_cosine_similarity(x, y)
# example 2
a <- c(1, 2, 3)
b <- c(1, 2, 40000)
calculate_cosine_similarity(a, b)
# Let's do it with texts
obama_text <- texts(corpus_subset(data_corpus_inaugural,
President == "Obama"))
lincoln_text <- texts(corpus_subset(data_corpus_inaugural,
President == "Lincoln"))
# Make a dfm of these two
obama_lincoln_dfm <- dfm(c(obama_text, lincoln_text),
remove = stopwords("english"), stem = TRUE)
# Calculate similarity
library(quanteda.textstats)
similarity_obama_lincoln_with_preprocessing <-
textstat_simil(obama_lincoln_dfm, margin = "documents", method = "cosine")
as.matrix(similarity_obama_lincoln_with_preprocessing)
obama_lincoln_no_preprocessing <- dfm(c(obama_text, lincoln_text))
similarity_obama_lincoln_with_no_preprocessing <-
textstat_simil(obama_lincoln_no_preprocessing, margin = "documents",
method = "cosine")
as.matrix(similarity_obama_lincoln_with_no_preprocessing)
# Other options available: Manhattan distance, correlation, etc.
?textstat_simil
